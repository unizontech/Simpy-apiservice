import simpy
import random
import statistics
from collections import defaultdict

class Server:
    def __init__(self, env, name, threads=4, ram_gb=32, disk_q=16, net_mbps=1000):
        self.env = env
        self.name = name
        self.cpu = simpy.PreemptiveResource(env, capacity=threads)
        self.ram = simpy.Container(env, capacity=ram_gb, init=ram_gb)
        self.disk = simpy.Resource(env, capacity=disk_q)
        self.net_mbps = net_mbps
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.total_requests = 0
        self.cpu_time = 0
        self.ram_usage = []
        self.response_times = []
    
    def process_request(self, cpu_ms=50, ram_gb=1, disk_mb=10, net_mb=5):
        start_time = self.env.now
        
        # ãƒ¡ãƒ¢ãƒªç¢ºä¿
        yield self.ram.get(ram_gb)
        
        try:
            # CPUå‡¦ç†
            with self.cpu.request() as req:
                yield req
                cpu_time = cpu_ms / 1000.0  # ms to seconds
                yield self.env.timeout(cpu_time)
                self.cpu_time += cpu_time
            
            # Disk I/Oï¼ˆå¿…è¦ãªå ´åˆï¼‰
            if disk_mb > 0:
                with self.disk.request() as dreq:
                    yield dreq
                    yield self.env.timeout(disk_mb / 500)  # 500MB/s assumed
            
            # Networkå‡¦ç†æ™‚é–“
            if net_mb > 0:
                yield self.env.timeout(net_mb / (self.net_mbps / 8))
                
        finally:
            # ãƒ¡ãƒ¢ãƒªè§£æ”¾
            yield self.ram.put(ram_gb)
            
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
        self.total_requests += 1
        self.response_times.append(self.env.now - start_time)
        self.ram_usage.append(self.ram.level)

class MicroserviceSystem:
    def __init__(self, env):
        self.env = env
        # ã‚µãƒ¼ãƒãƒ¼å®šç¾©ï¼ˆthreads: è«–ç†ãƒ—ãƒ­ã‚»ãƒƒã‚µæ•°ï¼‰
        self.nginx = Server(env, "Nginx", threads=8, ram_gb=16, net_mbps=40000)
        self.app1 = Server(env, "APP1", threads=16, ram_gb=64)
        self.auth = Server(env, "Auth", threads=4, ram_gb=32)
        self.policy = Server(env, "Policy", threads=8, ram_gb=32)
        self.service = Server(env, "Service", threads=16, ram_gb=64)
        self.db = Server(env, "DB", threads=32, ram_gb=128, disk_q=64)
        self.logger = Server(env, "Logger", threads=4, ram_gb=16)
        self.s3 = Server(env, "S3", threads=4, ram_gb=32, disk_q=128)
        self.servicehub = Server(env, "ServiceHub", threads=16, ram_gb=64)
        self.app2 = Server(env, "APP2", threads=16, ram_gb=64)
        
        # å…¨ä½“ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.total_requests = 0
        self.completed_requests = 0
        self.end_to_end_times = []

def service_with_db_flow(system):
    """Serviceâ†’DBä¾å­˜å‡¦ç†"""
    # Serviceå‡¦ç†
    yield system.env.process(system.service.process_request(cpu_ms=80, ram_gb=2))
    
    # 30%ã®ç¢ºç‡ã§DBå¿…è¦
    if random.random() < 0.3:
        yield system.env.process(system.db.process_request(
            cpu_ms=120, ram_gb=4, disk_mb=50, net_mb=2
        ))

def logger_to_s3_flow(system):
    """Loggerâ†’S3éåŒæœŸå‡¦ç†"""
    yield system.env.process(system.logger.process_request(cpu_ms=20, ram_gb=1))
    yield system.env.process(system.s3.process_request(
        cpu_ms=10, ram_gb=2, disk_mb=100, net_mb=20
    ))

def request_handler(system, request_id):
    """ãƒ¡ã‚¤ãƒ³ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†ãƒ•ãƒ­ãƒ¼"""
    start_time = system.env.now
    
    # 1. Nginxå‡¦ç†
    yield system.env.process(system.nginx.process_request(cpu_ms=10, net_mb=1))
    
    # 2. APP1å‡¦ç†é–‹å§‹
    yield system.env.process(system.app1.process_request(cpu_ms=60, ram_gb=2))
    
    # 3. ä¸¦åˆ—å‡¦ç†ï¼ˆAuth + Policy + Serviceï¼‰
    auth_task = system.env.process(system.auth.process_request(cpu_ms=40, ram_gb=1))
    policy_task = system.env.process(system.policy.process_request(cpu_ms=30, ram_gb=1))
    service_task = system.env.process(service_with_db_flow(system))
    
    # Auth/Policyå®Œäº†å¾…ã¡ï¼ˆå¿…é ˆï¼‰
    yield system.env.all_of([auth_task, policy_task])
    
    # Serviceå®Œäº†å¾…ã¡
    yield service_task
    
    # éåŒæœŸãƒ­ã‚°é–‹å§‹ï¼ˆå¾…ãŸãªã„ï¼‰
    system.env.process(logger_to_s3_flow(system))
    
    # 4. ServiceHubå‡¦ç†
    yield system.env.process(system.servicehub.process_request(cpu_ms=50, ram_gb=1))
    
    # 5. APP2æœ€çµ‚å‡¦ç†
    yield system.env.process(system.app2.process_request(cpu_ms=40, ram_gb=2))
    
    # å…¨ä½“ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²
    system.completed_requests += 1
    system.end_to_end_times.append(system.env.now - start_time)

def request_generator(system, arrival_rate=2.0, sim_time=100):
    """ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”Ÿæˆãƒ—ãƒ­ã‚»ã‚¹"""
    request_id = 0
    while system.env.now < sim_time:
        system.total_requests += 1
        system.env.process(request_handler(system, f"req_{request_id}"))
        request_id += 1
        yield system.env.timeout(random.expovariate(arrival_rate))

def run_simulation(arrival_rate=2.0, sim_time=100):
    """ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã¨çµæœåˆ†æ"""
    env = simpy.Environment()
    system = MicroserviceSystem(env)
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆç”Ÿæˆé–‹å§‹
    env.process(request_generator(system, arrival_rate, sim_time))
    
    # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    env.run(until=sim_time)
    
    # === çµæœåˆ†æï¼šã€Œä½•ãŒã‚ã‹ã‚‹ã‹ã€ ===
    print("=" * 60)
    print("ğŸ” ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ†æçµæœ")
    print("=" * 60)
    
    # å…¨ä½“æ€§èƒ½
    if system.end_to_end_times:
        print(f"\nğŸ“Š å…¨ä½“æ€§èƒ½")
        print(f"  ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {system.total_requests}")
        print(f"  å®Œäº†ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°: {system.completed_requests}")
        print(f"  æˆåŠŸç‡: {system.completed_requests/system.total_requests*100:.1f}%")
        print(f"  å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {statistics.mean(system.end_to_end_times):.3f}ç§’")
        if len(system.end_to_end_times) > 1:
            sorted_times = sorted(system.end_to_end_times)
            p95_idx = int(len(sorted_times) * 0.95)
            print(f"  P95ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {sorted_times[p95_idx]:.3f}ç§’")
    
    # å„ã‚µãƒ¼ãƒãƒ¼ã®è² è·åˆ†æ
    print(f"\nğŸ–¥ï¸  å„ã‚µãƒ¼ãƒãƒ¼è² è·åˆ†æ")
    servers = [system.nginx, system.app1, system.auth, system.policy, 
              system.service, system.db, system.logger, system.s3, 
              system.servicehub, system.app2]
    
    bottlenecks = []
    for server in servers:
        if server.total_requests > 0:
            cpu_util = (server.cpu_time / sim_time) * 100 / server.cpu.capacity
            avg_ram = statistics.mean(server.ram_usage) if server.ram_usage else 0
            ram_util = (server.ram.capacity - avg_ram) / server.ram.capacity * 100
            
            print(f"  {server.name:12} | "
                  f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆ:{server.total_requests:3} | "
                  f"CPUä½¿ç”¨ç‡:{cpu_util:5.1f}% | "
                  f"RAMä½¿ç”¨ç‡:{ram_util:5.1f}%")
            
            # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ¤å®š
            if cpu_util > 70:
                bottlenecks.append(f"{server.name}(CPU:{cpu_util:.1f}%)")
            if ram_util > 80:
                bottlenecks.append(f"{server.name}(RAM:{ram_util:.1f}%)")
    
    # ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
    print(f"\nâš ï¸  ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š")
    if bottlenecks:
        print(f"  æ¤œå‡ºã•ã‚ŒãŸãƒœãƒˆãƒ«ãƒãƒƒã‚¯: {', '.join(bottlenecks)}")
        print(f"  ğŸ’¡ æ”¹å–„ææ¡ˆ: ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚µãƒ¼ãƒãƒ¼ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ãƒƒãƒ—/ã‚¢ã‚¦ãƒˆæ¤œè¨")
    else:
        print(f"  âœ… ç¾åœ¨ã®è² è·ã§ã¯å•é¡Œãªã—")
        print(f"  ğŸ’¡ ã•ã‚‰ã«è² è·ã‚’ä¸Šã’ã¦ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£é™ç•Œã‚’ç‰¹å®šå¯èƒ½")
    
    # å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    print(f"\nğŸ”„ å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
    print(f"  ä¸¦åˆ—å‡¦ç†åŠ¹æœ: Auth/Policy/Serviceã®åŒæ™‚å®Ÿè¡Œ")
    print(f"  éåŒæœŸåŠ¹æœ: Loggerâ†’S3ãŒãƒ¡ã‚¤ãƒ³å‡¦ç†ã«å½±éŸ¿ã›ãš")
    print(f"  ä¾å­˜é–¢ä¿‚: Serviceâ†’DB (30%ç¢ºç‡) ã®æ¡ä»¶ä»˜ãå‡¦ç†")
    
    return system

# è¤‡æ•°ã‚·ãƒŠãƒªã‚ªã§ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ç‰¹å®š
def analyze_scaling():
    """è² è·ã‚’å¤‰ãˆã¦ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã‚’ç‰¹å®š"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æ")
    print("=" * 60)
    
    scenarios = [
        {"rate": 1.0, "name": "è»½è² è·"},
        {"rate": 3.0, "name": "ä¸­è² è·"}, 
        {"rate": 5.0, "name": "é«˜è² è·"},
        {"rate": 8.0, "name": "è¶…é«˜è² è·"}
    ]
    
    for scenario in scenarios:
        print(f"\nğŸ¯ {scenario['name']} (åˆ°ç€ç‡: {scenario['rate']} req/s)")
        system = run_simulation(arrival_rate=scenario['rate'], sim_time=60)
        
        if system.end_to_end_times:
            avg_response = statistics.mean(system.end_to_end_times)
            print(f"   â†’ å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {avg_response:.3f}ç§’")
            
            # SLOåˆ¤å®šï¼ˆä¾‹ï¼š300msä»¥ä¸‹ï¼‰
            slo_ok = avg_response < 0.3
            print(f"   â†’ SLO(300ms): {'âœ… OK' if slo_ok else 'âŒ NG'}")

if __name__ == "__main__":
    print("ğŸš€ SimPy ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    
    # åŸºæœ¬ã‚·ãƒŠãƒªã‚ªå®Ÿè¡Œ
    system = run_simulation(arrival_rate=3.0, sim_time=100)
    
    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°åˆ†æ
    analyze_scaling()
    
    print("\n" + "=" * 60)
    print("âœ¨ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
    print("ğŸ’¡ ã‚ã‹ã‚‹ã“ã¨:")
    print("  - ã©ã®ã‚µãƒ¼ãƒãƒ¼ãŒãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã«ãªã‚‹ã‹")
    print("  - ä½•req/sã¾ã§å‡¦ç†ã§ãã‚‹ã‹") 
    print("  - CPU/Memory/Diskã®ã©ã‚ŒãŒå…ˆã«é™ç•Œã«ãªã‚‹ã‹")
    print("  - ä¸¦åˆ—å‡¦ç†ãƒ»éåŒæœŸå‡¦ç†ã®åŠ¹æœ")
    print("  - SLOã‚’æº€ãŸã™ãŸã‚ã®å¿…è¦å°æ•°")
    print("=" * 60)